"""FastAPI ä¸»æœåŠ¡ - å¼‚æ­¥æ”¯æŒ + SSE è¿›åº¦æ¨é€"""
import os
import json
import asyncio
import tempfile
import logging
from pathlib import Path
from contextlib import asynccontextmanager
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware

from gpu_manager import gpu_manager

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

UPLOAD_FOLDER = tempfile.gettempdir()
ALLOWED_EXTENSIONS = {'wav', 'mp3', 'flac', 'm4a', 'ogg', 'webm'}

# å…¨å±€è¿›åº¦
progress_state = {"current": 0, "total": 0, "text": "", "done": False}


def allowed_file(filename: str) -> bool:
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


@asynccontextmanager
async def lifespan(app: FastAPI):
    # å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹
    logger.info("å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹...")
    checkpoint = os.environ.get('MODEL_CHECKPOINT', 'zai-org/GLM-ASR-Nano-2512')
    gpu_manager.load(checkpoint)
    yield
    # å…³é—­æ—¶æ¸…ç†
    gpu_manager.unload()


app = FastAPI(
    title="GLM-ASR API",
    description="""
## ğŸ¯ GLM-ASR è¯­éŸ³è¯†åˆ«æœåŠ¡

åŸºäº GLM-ASR-Nano-2512 æ¨¡å‹çš„é«˜ç²¾åº¦è¯­éŸ³è½¬æ–‡å­—æœåŠ¡ã€‚

### âœ¨ ç‰¹æ€§
- æ”¯æŒ 17 ç§è¯­è¨€ï¼ˆä¸­æ–‡ã€è‹±æ–‡ã€ç²¤è¯­ã€æ—¥è¯­ã€éŸ©è¯­ç­‰ï¼‰
- æ™ºèƒ½ VAD åˆ†æ®µï¼Œæ”¯æŒä»»æ„é•¿åº¦éŸ³é¢‘
- åŒæ¨¡å¼ APIï¼šåŒæ­¥è¿”å› / SSE æµå¼è¿”å›
- GPU æ˜¾å­˜ç®¡ç†ï¼Œæ”¯æŒæ‰‹åŠ¨åŠ è½½/å¸è½½æ¨¡å‹

### ğŸ“¦ æ”¯æŒæ ¼å¼
`wav`, `mp3`, `flac`, `m4a`, `ogg`, `webm`

### ğŸ”— ç›¸å…³é“¾æ¥
- [GitHub](https://github.com/neosun100/glm-asr)
- [Docker Hub](https://hub.docker.com/r/neosun/glm-asr)
""",
    version="2.0.1",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])


# ==================== é™æ€æ–‡ä»¶ ====================
@app.get("/", include_in_schema=False)
async def index():
    return FileResponse("static/index.html")

app.mount("/static", StaticFiles(directory="static"), name="static")


# ==================== ç³»ç»Ÿ API ====================
@app.get("/health", tags=["ç³»ç»Ÿ"], summary="å¥åº·æ£€æŸ¥",
    description="æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œï¼Œä»¥åŠæ¨¡å‹æ˜¯å¦å·²åŠ è½½ã€‚",
    responses={200: {"description": "æœåŠ¡çŠ¶æ€", "content": {"application/json": {"example": {"status": "ok", "model_loaded": True}}}}})
async def health():
    return {"status": "ok", "model_loaded": gpu_manager.model is not None}


# ==================== GPU ç®¡ç† ====================
@app.get("/gpu/status", tags=["GPUç®¡ç†"], summary="è·å–GPUçŠ¶æ€",
    description="è·å–å½“å‰ GPU æ˜¾å­˜ä½¿ç”¨æƒ…å†µå’Œæ¨¡å‹åŠ è½½çŠ¶æ€ã€‚",
    responses={200: {"description": "GPUçŠ¶æ€ä¿¡æ¯", "content": {"application/json": {"example": {
        "model_loaded": True, "device": "cuda", "checkpoint": "zai-org/GLM-ASR-Nano-2512",
        "gpu_memory_used_mb": 4320.5, "gpu_memory_total_mb": 24576.0}}}}})
async def gpu_status():
    return gpu_manager.get_status()


@app.post("/gpu/load", tags=["GPUç®¡ç†"], summary="åŠ è½½æ¨¡å‹",
    description="å°†æ¨¡å‹åŠ è½½åˆ° GPU æ˜¾å­˜ã€‚å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨åŠ è½½ï¼Œä¸€èˆ¬æ— éœ€æ‰‹åŠ¨è°ƒç”¨ã€‚",
    responses={200: {"description": "åŠ è½½æˆåŠŸ", "content": {"application/json": {"example": {"status": "loaded", "model_loaded": True}}}}})
async def gpu_load():
    gpu_manager.load('zai-org/GLM-ASR-Nano-2512')
    return {"status": "loaded", **gpu_manager.get_status()}


@app.post("/gpu/unload", tags=["GPUç®¡ç†"], summary="å¸è½½æ¨¡å‹",
    description="ä» GPU æ˜¾å­˜ä¸­å¸è½½æ¨¡å‹ï¼Œé‡Šæ”¾æ˜¾å­˜ã€‚éœ€è¦å†æ¬¡ä½¿ç”¨æ—¶è°ƒç”¨ `/gpu/load` é‡æ–°åŠ è½½ã€‚",
    responses={200: {"description": "å¸è½½æˆåŠŸ", "content": {"application/json": {"example": {"status": "unloaded"}}}}})
async def gpu_unload():
    return gpu_manager.unload()


# ==================== è½¬å½• API ====================
@app.post("/api/transcribe", tags=["è¯­éŸ³è½¬å½•"], summary="åŒæ­¥è½¬å½•ï¼ˆæ¨èçŸ­éŸ³é¢‘ï¼‰",
    description="""
å°†éŸ³é¢‘æ–‡ä»¶è½¬å½•ä¸ºæ–‡å­—ï¼Œç­‰å¾…å¤„ç†å®Œæˆåä¸€æ¬¡æ€§è¿”å›ç»“æœã€‚

**é€‚ç”¨åœºæ™¯ï¼š** çŸ­éŸ³é¢‘ï¼ˆ< 1åˆ†é’Ÿï¼‰

**å¤„ç†æµç¨‹ï¼š**
1. ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
2. æœåŠ¡å™¨å¤„ç†ï¼ˆçŸ­éŸ³é¢‘ç›´æ¥å¤„ç†ï¼Œé•¿éŸ³é¢‘è‡ªåŠ¨ VAD åˆ†æ®µï¼‰
3. è¿”å›å®Œæ•´è½¬å½•ç»“æœ

**æ³¨æ„ï¼š** é•¿éŸ³é¢‘å¤„ç†æ—¶é—´è¾ƒé•¿ï¼Œå¯èƒ½å¯¼è‡´è¯·æ±‚è¶…æ—¶ï¼Œå»ºè®®ä½¿ç”¨ `/api/transcribe/stream` æµå¼æ¥å£ã€‚
""",
    responses={
        200: {"description": "è½¬å½•æˆåŠŸ", "content": {"application/json": {"example": {"status": "success", "text": "è¿™æ˜¯è½¬å½•å‡ºæ¥çš„æ–‡å­—å†…å®¹ã€‚"}}}},
        400: {"description": "æ— æ•ˆçš„æ–‡ä»¶æ ¼å¼", "content": {"application/json": {"example": {"detail": "æ— æ•ˆçš„æ–‡ä»¶æ ¼å¼"}}}},
        503: {"description": "æ¨¡å‹æœªåŠ è½½", "content": {"application/json": {"example": {"detail": "æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆåŠ è½½æ¨¡å‹"}}}}
    })
async def transcribe(
    file: UploadFile = File(..., description="éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒ wav/mp3/flac/m4a/ogg/webmï¼‰"),
    max_new_tokens: int = Form(512, description="æœ€å¤§ç”Ÿæˆ token æ•°ï¼Œå½±å“è¾“å‡ºé•¿åº¦ï¼Œå»ºè®® 256-1024", ge=1, le=2048)
):
    if not file.filename or not allowed_file(file.filename):
        raise HTTPException(400, "æ— æ•ˆçš„æ–‡ä»¶æ ¼å¼")
    
    filepath = os.path.join(UPLOAD_FOLDER, file.filename)
    content = await file.read()
    with open(filepath, 'wb') as f:
        f.write(content)
    
    try:
        result = gpu_manager.transcribe(filepath, max_new_tokens)
        return {"status": "success", "text": result}
    except RuntimeError as e:
        raise HTTPException(503, str(e))
    except Exception as e:
        raise HTTPException(500, f"è½¬å½•å¤±è´¥: {str(e)}")
    finally:
        if os.path.exists(filepath):
            os.remove(filepath)


@app.post("/api/transcribe/stream", tags=["è¯­éŸ³è½¬å½•"], summary="SSE æµå¼è½¬å½•ï¼ˆæ¨èé•¿éŸ³é¢‘ï¼‰",
    description="""
ä½¿ç”¨ Server-Sent Events (SSE) æµå¼è¿”å›è½¬å½•è¿›åº¦å’Œç»“æœï¼Œé¿å…é•¿éŸ³é¢‘å¤„ç†è¶…æ—¶ã€‚

**é€‚ç”¨åœºæ™¯ï¼š** é•¿éŸ³é¢‘ï¼ˆ> 1åˆ†é’Ÿï¼‰

**SSE äº‹ä»¶ç±»å‹ï¼š**

| type | è¯´æ˜ | æ•°æ®ç¤ºä¾‹ |
|------|------|----------|
| `start` | å¼€å§‹å¤„ç† | `{}` |
| `progress` | å¤„ç†è¿›åº¦ | `{"current": 3, "total": 10, "duration": 22.5}` |
| `partial` | åˆ†æ®µç»“æœ | `{"text": "è¿™æ˜¯ç¬¬ä¸‰æ®µçš„æ–‡å­—..."}` |
| `heartbeat` | å¿ƒè·³ä¿æ´» | `{}` |
| `done` | å¤„ç†å®Œæˆ | `{"text": "å®Œæ•´çš„è½¬å½•ç»“æœ..."}` |
| `error` | å¤„ç†å‡ºé”™ | `{"message": "é”™è¯¯ä¿¡æ¯"}` |

**è°ƒç”¨ç¤ºä¾‹ï¼ˆcurlï¼‰ï¼š**
```bash
curl -X POST http://localhost:7860/api/transcribe/stream \\
  -F "file=@long_audio.mp3" \\
  -F "max_new_tokens=512"
```

**è°ƒç”¨ç¤ºä¾‹ï¼ˆJavaScriptï¼‰ï¼š**
```javascript
const formData = new FormData();
formData.append('file', audioFile);
formData.append('max_new_tokens', 512);

const response = await fetch('/api/transcribe/stream', {
  method: 'POST',
  body: formData
});

const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  const chunk = decoder.decode(value);
  // è§£æ SSE æ•°æ®: data: {"type": "progress", ...}
  console.log(chunk);
}
```
""",
    responses={
        200: {"description": "SSE æµå¼å“åº”", "content": {"text/event-stream": {"example": 'data: {"type": "progress", "current": 1, "total": 5, "duration": 20.5}\n\ndata: {"type": "partial", "text": "è½¬å½•æ–‡å­—..."}\n\ndata: {"type": "done", "text": "å®Œæ•´ç»“æœ"}'}}},
        400: {"description": "æ— æ•ˆçš„æ–‡ä»¶æ ¼å¼"}
    })
async def transcribe_stream(
    file: UploadFile = File(..., description="éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒ wav/mp3/flac/m4a/ogg/webmï¼‰"),
    max_new_tokens: int = Form(512, description="æœ€å¤§ç”Ÿæˆ token æ•°", ge=1, le=2048)
):
    if not file.filename or not allowed_file(file.filename):
        raise HTTPException(400, "æ— æ•ˆçš„æ–‡ä»¶æ ¼å¼")
    
    filepath = os.path.join(UPLOAD_FOLDER, file.filename)
    content = await file.read()
    with open(filepath, 'wb') as f:
        f.write(content)
    
    async def generate():
        loop = asyncio.get_event_loop()
        progress_queue = asyncio.Queue()
        
        def on_progress(current, total, duration, text):
            asyncio.run_coroutine_threadsafe(
                progress_queue.put({"current": current, "total": total, "duration": duration, "text": text}),
                loop
            )
        
        async def do_transcribe():
            try:
                result = await loop.run_in_executor(
                    None, lambda: gpu_manager.transcribe(filepath, max_new_tokens, on_progress)
                )
                await progress_queue.put({"done": True, "result": result})
            except Exception as e:
                await progress_queue.put({"error": str(e)})
            finally:
                if os.path.exists(filepath):
                    os.remove(filepath)
        
        task = asyncio.create_task(do_transcribe())
        yield f"data: {json.dumps({'type': 'start'})}\n\n"
        
        while True:
            try:
                msg = await asyncio.wait_for(progress_queue.get(), timeout=0.5)
                if "error" in msg:
                    yield f"data: {json.dumps({'type': 'error', 'message': msg['error']})}\n\n"
                    break
                elif "done" in msg:
                    yield f"data: {json.dumps({'type': 'done', 'text': msg['result']})}\n\n"
                    break
                else:
                    yield f"data: {json.dumps({'type': 'progress', 'current': msg['current'], 'total': msg['total'], 'duration': round(msg['duration'], 1)})}\n\n"
                    if msg['text']:
                        yield f"data: {json.dumps({'type': 'partial', 'text': msg['text']})}\n\n"
            except asyncio.TimeoutError:
                if task.done():
                    break
                yield f"data: {json.dumps({'type': 'heartbeat'})}\n\n"
        
        await task
    
    return StreamingResponse(generate(), media_type="text/event-stream")


if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get('PORT', 7860))
    logger.info(f"æœåŠ¡å¯åŠ¨: http://0.0.0.0:{port}")
    uvicorn.run(app, host="0.0.0.0", port=port)
